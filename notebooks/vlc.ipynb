{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import functools\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as tf\n",
    "from torchvision.datasets import MNIST, CIFAR10, CIFAR100\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "\n",
    "import tyxe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ROOT = os.environ.get(\"DATASETS_PATH\", \"./data\")\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\") if USE_CUDA else torch.device(\"cpu\")\n",
    "C10_MEAN = (0.49139968, 0.48215841, 0.44653091)\n",
    "C10_SD = (0.24703223, 0.24348513, 0.26158784)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_3x3(c_in, c_out):\n",
    "    return nn.Conv2d(c_in, c_out, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "\n",
    "class ConvNet(nn.Sequential):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add_module(\"Conv1_1\", conv_3x3(3, 32))\n",
    "        self.add_module(\"ReLU1_1\", nn.ReLU(inplace=True))\n",
    "        self.add_module(\"Conv1_2\", conv_3x3(32, 32))\n",
    "        self.add_module(\"ReLU1_2\", nn.ReLU(inplace=True))\n",
    "        self.add_module(\"MaxPool1\", nn.MaxPool2d(2, stride=2))\n",
    "\n",
    "        self.add_module(\"Conv2_1\", conv_3x3(32, 64))\n",
    "        self.add_module(\"ReLU2_1\", nn.ReLU(inplace=True))\n",
    "        self.add_module(\"Conv2_2\", conv_3x3(64, 64))\n",
    "        self.add_module(\"ReLU2_2\", nn.ReLU(inplace=True))\n",
    "        self.add_module(\"MaxPool2\", nn.MaxPool2d(2, stride=2))\n",
    "\n",
    "        self.add_module(\"Flatten\", nn.Flatten())\n",
    "\n",
    "        self.add_module(\"Linear\", nn.Linear(64 * 8 * 8, 512))\n",
    "        self.add_module(\"ReLU\", nn.ReLU(inplace=True))\n",
    "\n",
    "        self.add_module(\"Head\", nn.Linear(512, 10))\n",
    "\n",
    "\n",
    "class FCNet(nn.Sequential):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add_module(\"Linear\", nn.Linear(784, 200))\n",
    "        self.add_module(\"ReLU\", nn.ReLU(inplace=True))\n",
    "        self.add_module(\"Head\", nn.Linear(200, 1))\n",
    "\n",
    "\n",
    "def make_mnist_dataloaders(root, train_batch_size, test_batch_size):\n",
    "    train_loaders = []\n",
    "    test_loaders = []\n",
    "\n",
    "    for train, loaders, bs in zip((True, False), (train_loaders, test_loaders), (train_batch_size, test_batch_size)):\n",
    "        mnist = MNIST(os.path.join(root, \"mnist\"), train=train, download=True)\n",
    "        x = mnist.data.flatten(1) / 255.\n",
    "        y = mnist.targets\n",
    "        for i in range(5):\n",
    "            index = y.ge(i * 2) & y.lt((i + 1) * 2)\n",
    "            loaders.append(data.DataLoader(data.TensorDataset(x[index], y[index].sub(2 * i).float().unsqueeze(-1)),\n",
    "                                           bs, shuffle=True, pin_memory=USE_CUDA))\n",
    "\n",
    "    return train_loaders, test_loaders\n",
    "\n",
    "\n",
    "def make_cifar_dataloaders(root, train_batch_size, test_batch_size):\n",
    "    train_loaders = []\n",
    "    test_loaders = []\n",
    "\n",
    "    c100_means = []\n",
    "    c100_sds = []\n",
    "    for train, loaders, bs in zip((True, False), (train_loaders, test_loaders), (train_batch_size, test_batch_size)):\n",
    "        c10 = CIFAR10(os.path.join(root, \"cifar10\"), train=train,\n",
    "                      transform=tf.Compose([tf.ToTensor(), tf.Normalize(C10_MEAN, C10_SD)]))\n",
    "        loaders.append(data.DataLoader(c10, bs, shuffle=train, pin_memory=USE_CUDA))\n",
    "\n",
    "        c100 = CIFAR100(os.path.join(root, \"cifar100\"), train=train)\n",
    "        unnormalized_data = torch.from_numpy(c100.data).permute(0, 3, 1, 2).div(255.)  # convert images to torch arrays\n",
    "        targets = torch.tensor(c100.targets)\n",
    "\n",
    "        for i in range(5):\n",
    "            index = targets.ge(i * 10) & targets.lt((i + 1) * 10)\n",
    "\n",
    "            unnormalized_data_i = unnormalized_data[index]\n",
    "            if train:\n",
    "                c100_means.append(unnormalized_data_i.mean((0, 2, 3), keepdims=True))\n",
    "                c100_sds.append(unnormalized_data_i.std((0, 2, 3), keepdims=True))\n",
    "            normalized_data_i = (unnormalized_data_i - c100_means[i]) / c100_sds[i]\n",
    "            targets_i = targets[index] - i * 10\n",
    "\n",
    "            dataset_i = data.TensorDataset(normalized_data_i, targets_i)\n",
    "            loaders.append(data.DataLoader(dataset_i, bs, shuffle=train, pin_memory=USE_CUDA))\n",
    "\n",
    "    return train_loaders, test_loaders\n",
    "\n",
    "\n",
    "def main(root, dataset, inference):\n",
    "    train_batch_size = 250\n",
    "    test_batch_size = 1000\n",
    "\n",
    "    if dataset == \"cifar\":\n",
    "        net = ConvNet()\n",
    "        obs = tyxe.likelihoods.Categorical(-1)\n",
    "        train_loaders, test_loaders = make_cifar_dataloaders(root, train_batch_size, test_batch_size)\n",
    "        num_epochs = 60\n",
    "    elif dataset == \"mnist\":\n",
    "        net = FCNet()\n",
    "        obs = tyxe.likelihoods.Bernoulli(-1, event_dim=1)\n",
    "        train_loaders, test_loaders = make_mnist_dataloaders(root, train_batch_size, test_batch_size)\n",
    "        num_epochs = 600\n",
    "    else:\n",
    "        raise RuntimeError(\"Unreachable\")\n",
    "\n",
    "    net.to(DEVICE)\n",
    "    if inference == \"mean-field\":\n",
    "        prior = tyxe.priors.IIDPrior(dist.Normal(torch.tensor(\n",
    "            0., device=DEVICE), torch.tensor(1., device=DEVICE)),\n",
    "            expose_all=False, hide_modules=[net.Head])\n",
    "        guide = functools.partial(\n",
    "            tyxe.guides.AutoNormal, init_scale=1e-4,\n",
    "            init_loc_fn=tyxe.guides.PretrainedInitializer.from_net(net))\n",
    "        test_samples = 8\n",
    "    elif inference == \"ml\":\n",
    "        prior = tyxe.priors.IIDPrior(dist.Normal(0, 1), expose_all=False, hide_all=True)\n",
    "        guide = None\n",
    "    else:\n",
    "        raise RuntimeError(\"Unreachable\")\n",
    "    bnn = tyxe.VariationalBNN(net, prior, obs, guide)\n",
    "\n",
    "    n_tasks = len(train_loaders)\n",
    "    test_errors = torch.ones(n_tasks, n_tasks)\n",
    "\n",
    "    head_state_dicts = []\n",
    "    init_head_sd = copy.deepcopy(net.Head.state_dict())\n",
    "    for i, train_loader in enumerate(train_loaders, 1):\n",
    "        elbos = []\n",
    "        net.Head.load_state_dict(init_head_sd)\n",
    "\n",
    "        pbar = tqdm(total=num_epochs, unit=\"Epochs\", postfix=f\"Task {i}\")\n",
    "\n",
    "        def callback(_i, _ii, e):\n",
    "            elbos.append(e / len(train_loader.sampler))\n",
    "            pbar.update()\n",
    "\n",
    "        obs.dataset_size = len(train_loader.sampler)\n",
    "        optim = pyro.optim.Adam({\"lr\": 1e-3})\n",
    "        with tyxe.poutine.local_reparameterization():\n",
    "            bnn.fit(train_loader, optim, num_epochs, device=DEVICE, callback=callback)\n",
    "\n",
    "        pbar.close()\n",
    "\n",
    "        head_state_dicts.append(copy.deepcopy(net.Head.state_dict()))\n",
    "        for j, (test_loader, head_params) in enumerate(zip(test_loaders, head_state_dicts)):\n",
    "            net.Head.load_state_dict(head_params)\n",
    "            err = sum(bnn.evaluate(x.to(DEVICE), y.to(DEVICE), num_predictions=8)[0] for x, y in test_loader)\n",
    "            test_errors[i-1, j] = err / len(test_loader.sampler)\n",
    "\n",
    "        print(\"\\t\".join([\"Error\"] + [f\"Task {j}\" for j in range(1, i+1)]))\n",
    "        print(\"\\t\" + \"\\t\".join([f\"{100 * e:.2f}%\" for e in test_errors[i-1, :i]]))\n",
    "\n",
    "        if inference == \"mean-field\":\n",
    "            bnn.update_prior(tyxe.priors.DictPrior(bnn.net_guide.get_detached_distributions(\n",
    "                tyxe.util.pyro_sample_sites(bnn.net))))\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument(\"--root\", default=ROOT)\n",
    "#     parser.add_argument(\"--dataset\", choices=[\"mnist\", \"cifar\"], required=True)\n",
    "#     parser.add_argument(\"--inference\", choices=[\"mean-field\", \"ml\"], required=True)\n",
    "\n",
    "#     main(**vars(parser.parse_args()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(ROOT, \"mnist\", \"mean-field\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(ROOT, \"mnist\", \"ml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.38 + 29.77 + 2.03 + 2.11 + 1.36) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.05 + 43.44 + 0.48 + 1.66 + 0.45) / 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('tyxe')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e8b746a8311f1ca0a88d9ac835a0b13cb2eeabaa3ffb77d4d6963e5660a652f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
